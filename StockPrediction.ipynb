{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StockPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTC3/p9QOqO8lpABSGe1YG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaishnavi-Dixit-12/Stock-Prediction-using-LSTM-RNN-and-Tensorflow-2-/blob/main/StockPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UzDsoE_Ug8G"
      },
      "source": [
        "This is a Stock Prediction System using LSTM and Tensorflow 2\n",
        "(reference from: https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeRVxf8kIZor"
      },
      "source": [
        "#!pip3 install tensorflow pandas numpy matplotlib yahoo_fin sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFGrEelyKB6z"
      },
      "source": [
        "Uncomment and run the above line of code if the following modules are not installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_7TAAZxIoIJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "from google.colab import drive"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZwT2gCNJ1k2"
      },
      "source": [
        "* tensorflow - TensorFlow is an end-to-end open source platform for machine learning\n",
        "* os - the OS module in Python provides functions for interacting with the operating system.\n",
        "* numpy - library that provides a simple yet powerful data structure: the n-dimensional array.\n",
        "* pandas - it is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n",
        "built on top of the Python programming language.\n",
        "* random - this module implements pseudo-random number generators for various distributions.\n",
        "* matplotlib.pyplot - matplotlib.pyplot is a state-based interface to matplotlib. It provides a MATLAB-like way of plotting.\n",
        "* time - This module provides various time-related functions.\n",
        "\n",
        "-> yahoo_fin:http://theautomatic.net/yahoo_fin-documentation/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2EaTfoHJ6zF"
      },
      "source": [
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MElJE6FzKt7-"
      },
      "source": [
        "**The set.seed()**: *function sets the starting number used to generate a sequence of random numbers â€“ it ensures that you get the same result if you start with that same seed each time you run the same process.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWSg7DVlLZxo"
      },
      "source": [
        "#Dataset\n",
        "\n",
        "#shuffle them in unison with respect to their leading indices.\n",
        "def shuffle_in_unison(a,b):\n",
        "  state= np.random.get-state()\n",
        "  np.random.shuffle(a)\n",
        "  np.random.set_state(state)\n",
        "  np.random.shuffle(b)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0eF-iLoei0h"
      },
      "source": [
        "In the below function we will mainly look at:\n",
        "* -> Check whether the dataframe is already loaded or not\n",
        "* -> Check feature_columns are present in dataframe\n",
        "* -> Split the data into train and test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTKyfqw_fwNY"
      },
      "source": [
        "Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
        "    Params:\n",
        "* ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
        "* n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
        "* scale (bool): whether to scale prices from 0 to 1, default is True\n",
        "* shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
        "* lookup_step (int): the future lookup step to predict, default is 1 \n",
        "* split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
        "  to False will split datasets in a random way\n",
        "* test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
        "* feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVLD4U-VnrCD"
      },
      "source": [
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True, test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "  if isinstance(ticker, str):\n",
        "    df = si.get_data(ticker) #loads the dataframe into df\n",
        "    print('\\nloading data')\n",
        "  elif isinstance(ticker, pd.DataFrame):\n",
        "    df = ticker\n",
        "    print('data already loaded')\n",
        "  else:\n",
        "    raise TypeError(\"Incorrect Ticker\")\n",
        "  #checks if the ticker(i.e. the dataframe) we want to load is already present or not\n",
        "  \n",
        "  print('\\nData loading complete\\n\\n')\n",
        "  print(\"sample data:\\n\",df.head(),'\\n')\n",
        "  print('data shape->', df.shape)\n",
        "  result ={}\n",
        "  result['df'] = df.copy()\n",
        "  #return the original dataframe\n",
        "\n",
        "  #feature_column:\n",
        "  for column in feature_columns:\n",
        "    assert column in df.columns, print(f\"'{column}' does not exist in the dataframe.\") \n",
        "  if 'date' not in df.columns:\n",
        "    df['date'] = df.index\n",
        "  if scale:\n",
        "    column_scaler ={} \n",
        "    #scale data from 0 to 1\n",
        "\n",
        "    for column in feature_columns:\n",
        "      scaler = preprocessing.MinMaxScaler() \n",
        "      #This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.\n",
        "      df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "      column_scaler[column] = scaler\n",
        "    result[\"column_scaler\"] = column_scaler\n",
        "  \n",
        "  #checks whether the passed feature_columns exist in dataframe (line 15), add date as column(line 17)\n",
        "  \n",
        "  df['future'] =df['adjclose'].shift(-lookup_step) \n",
        "  #(look_up = 1) DataFrame.shift(periods=1, freq=None, axis=0, fill_value=<object object>) - Shift index by desired number of periods with an optional time freq.\n",
        "\n",
        "  last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "  df.dropna(inplace=True) #drop NaNs (Not A Number)\n",
        "\n",
        "  sequence_data = []\n",
        "  sequences = deque(maxlen=n_steps)\n",
        "  for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
        "    sequences.append(entry)\n",
        "    if len(sequences) == n_steps:\n",
        "        sequence_data.append([np.array(sequences), target])\n",
        "    # Once a bounded length deque is full, when new items are added, a corresponding number of items are discarded from the opposite end. \n",
        "    # if n_steps=x and lookup_step=y, last_sequence should be of x+y length\n",
        "  \n",
        "  last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
        "  last_sequence = np.array(last_sequence).astype(np.float32)\n",
        "  result['last_sequence']= last_sequence #add to result\n",
        "  # last_sequence will predict future prices that are not mentioned in the dataframe\n",
        "\n",
        "  #X and y\n",
        "  X,y =[],[]\n",
        "  for sequence, target in sequence_data:\n",
        "    X.append(sequence)\n",
        "    y.append(target)\n",
        "  # convert to np \n",
        "  X= np.array(X)\n",
        "  y= np.array(y)\n",
        "\n",
        "  #splitting the data\n",
        "  if split_by_date:\n",
        "      train_samples = int((1 - test_size) * len(X))\n",
        "      result[\"X_train\"] = X[:train_samples]\n",
        "      result[\"y_train\"] = y[:train_samples]\n",
        "      result[\"X_test\"]  = X[train_samples:]\n",
        "      result[\"y_test\"]  = y[train_samples:]\n",
        "      # split the dataset into training & testing sets by date (not randomly splitting)\n",
        "      \n",
        "      if shuffle:\n",
        "          # shuffle the datasets for training (NOTE: if shuffle parameter is set)\n",
        "          shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
        "          shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
        "  else:    \n",
        "      # split the dataset randomly\n",
        "      result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
        "    \n",
        "    \n",
        "  dates = result[\"X_test\"][:, -1, -1]\n",
        "  result[\"test_df\"] = result[\"df\"].loc[dates]\n",
        "  result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
        "  result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
        "  result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
        "  \n",
        "  return result    \n",
        "                                                \n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzJysDNWCJlr"
      },
      "source": [
        "* **Create Model:**\n",
        "the below function is flexible, we can change the values of the parameters in the function.\n",
        "The function will create a RNN that has a dense layer as output layer with 1 neuro. \n",
        "\n",
        "* **Bidirectional Layer:** Bidirectional RNNs\n",
        "For sequences other than time series (e.g. text), it is often the case that a RNN model can perform better if it not only processes sequence from start to end, but also backwards. For example, to predict the next word in a sentence, it is often useful to have the context around the word, not only just the words that come before it.\n",
        "Keras provides an easy API for you to build such bidirectional RNNs: the keras.layers.Bidirectional wrapper.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfcQxeRzN05e"
      },
      "source": [
        "#Creating model\n",
        "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
        "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
        "    \n",
        "    model = Sequential()\n",
        "    #A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
        "  \n",
        "    #layers\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
        "        elif i == n_layers - 1:\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # if condition: first layer; elif condition: last layer; else condition: hidden layers\n",
        "        \n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2FjmM3hN1-w"
      },
      "source": [
        "#load_data parameters\n",
        "N_STEPS = 50 # Window size or the sequence length\n",
        "LOOKUP_STEP = 15 # Lookup step, 1 is the next day \n",
        "#(value of stock after '15'(value of lookup step) will be predicted)\n",
        "SCALE = True # whether to scale feature columns & output price as well\n",
        "SHUFFLE = True # whether to shuffle the dataset\n",
        "SPLIT_BY_DATE = False # whether to split the training/testing set by date\n",
        "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
        "\n",
        "TEST_SIZE = 0.2 # test ratio size, 0.2 is 20%\n",
        "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"] # features to use\n",
        "\n",
        "date_now = time.strftime(\"%Y-%m-%d\") # date now\n",
        "\n",
        "\n",
        "#create_model parameters\n",
        "N_LAYERS = 2 \n",
        "CELL = LSTM # LSTM cell\n",
        "UNITS = 256 # 256 LSTM neurons\n",
        "DROPOUT = 0.4 \n",
        "BIDIRECTIONAL = False # whether to use bidirectional RNNs\n",
        "\n",
        "\n",
        "# training parameters\n",
        "LOSS = \"huber_loss\"\n",
        "OPTIMIZER = \"adam\"\n",
        "BATCH_SIZE = 64 #try changing the value and observe changes in predicted value\n",
        "EPOCHS = 1 #Try ranging this value from 10-500 and analysis its effect on the accuracy for predicted value\n",
        "\n",
        "# select the ticker\n",
        "ticker = \"MSFT\" #try with values like NFLX, INFY etc.\n",
        "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "\n",
        "# model name\n",
        "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
        "scale_str = f\"sc-{int(SCALE)}\"\n",
        "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
        "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "if BIDIRECTIONAL:\n",
        "    model_name += \"-b\""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsGT9GkSN8T9"
      },
      "source": [
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfmYUfbM_x-t",
        "outputId": "f93ee703-4c54-4e11-e93c-144867bc191f"
      },
      "source": [
        "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
        "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
        "                feature_columns=FEATURE_COLUMNS)\n",
        "#loads the data"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "loading data\n",
            "\n",
            "Data loading complete\n",
            "\n",
            "\n",
            "sample data:\n",
            "                 open      high       low     close  adjclose      volume ticker\n",
            "1986-03-13  0.088542  0.101563  0.088542  0.097222  0.061608  1031788800   MSFT\n",
            "1986-03-14  0.097222  0.102431  0.097222  0.100694  0.063809   308160000   MSFT\n",
            "1986-03-17  0.100694  0.103299  0.100694  0.102431  0.064909   133171200   MSFT\n",
            "1986-03-18  0.102431  0.103299  0.098958  0.099826  0.063258    67766400   MSFT\n",
            "1986-03-19  0.099826  0.100694  0.097222  0.098090  0.062158    47894400   MSFT \n",
            "\n",
            "data shape-> (8877, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmbLfO1a_1-W"
      },
      "source": [
        "data[\"df\"].to_csv(ticker_data_filename)\n",
        "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "#save dataframe and construct model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyvioQnkK-RL"
      },
      "source": [
        "* **ModelCheckpoin**t callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved.\n",
        "* **TensorBoard** provides the visualization and tooling needed for machine learning experimentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th99xRivOBjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078b8f1a-e72d-4df4-f3fb-1b11f028135a"
      },
      "source": [
        "checkpoint = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                    callbacks=[checkpoint, tensorboard],\n",
        "                    verbose=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 66s 568ms/step - loss: 0.0010 - mean_absolute_error: 0.0231 - val_loss: 1.3595e-04 - val_mean_absolute_error: 0.0110\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00014, saving model to results/2021-06-02_MSFT-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl3dJDvUOeUW"
      },
      "source": [
        "#plot graph\n",
        "def plot_graph(test_df):\n",
        "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
        "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
        "    plt.xlabel(\"Days\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dFeBTQYMzPx"
      },
      "source": [
        "In the below get_final_df function\n",
        "* This function takes the `model` and `data` dict to construct a final dataframe that includes the features along with true and predicted prices of the testing dataset\n",
        "* \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-dPHYaqOg7Q"
      },
      "source": [
        "def get_final_df(model, data):\n",
        "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
        "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
        "\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_test = data[\"y_test\"]\n",
        "    \n",
        "    y_pred = model.predict(X_test) #predict data\n",
        "    if SCALE:\n",
        "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    test_df = data[\"test_df\"]\n",
        "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred # add predicted future prices to the dataframe\n",
        "   \n",
        "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test  # add true future prices to the dataframe\n",
        "    \n",
        "    test_df.sort_index(inplace=True) # sort the dataframe by date\n",
        "    final_df = test_df\n",
        "    \n",
        "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
        "                                    final_df[\"adjclose\"], \n",
        "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
        "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
        "                                    # since we don't have profit for last sequence, add 0's\n",
        "                                    ) # add the buy profit column\n",
        "    \n",
        "    \n",
        "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
        "                                    final_df[\"adjclose\"], \n",
        "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
        "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
        "                                    # since we don't have profit for last sequence, add 0's\n",
        "                                    ) # add the sell profit column\n",
        "\n",
        "    return final_df"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HV4sVdBOi8S"
      },
      "source": [
        "def predict(model, data):\n",
        "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
        "    print(last_sequence)\n",
        "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "   \n",
        "    prediction = model.predict(last_sequence)  # get the prediction (scaled from 0 to 1)\n",
        "    if SCALE:\n",
        "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
        "    else:\n",
        "        predicted_price = prediction[0][0]\n",
        "\n",
        "    # inverting and scaling to get the price\n",
        "    return predicted_price"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFq_oT1lOtes"
      },
      "source": [
        "For the below block of code\n",
        "* **model.evaluate()**: Returns the loss value & metrics values for the model in test mode.\n",
        "* mean absolute error: In statistics, mean absolute error (MAE) is a measure of errors between paired observations expressing the same phenomenon. here mean absolute error is also known as inverse scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq4JbUvPOmkz"
      },
      "source": [
        "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "\n",
        "if SCALE:\n",
        "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "else:\n",
        "    mean_absolute_error = mae"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M2QXGuMOqc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b505e7fc-582c-4d72-91ce-e72529530503"
      },
      "source": [
        "final_df = get_final_df(model, data)\n",
        "future_price = predict(model, data)\n",
        "\n",
        "#Here we get the final data frame and our predicyed values for the given dataframe"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9008066  0.02702614 0.8799946  0.9000752  0.88453615]\n",
            " [0.90687734 0.02849425 0.90759695 0.91584885 0.9111816 ]\n",
            " [0.898783   0.02264832 0.9089733  0.9042562  0.904453  ]\n",
            " [0.8868706  0.03084834 0.89922446 0.9002273  0.89003444]\n",
            " [0.9026774  0.02251213 0.88488805 0.8993531  0.88995755]\n",
            " [0.8979431  0.02226696 0.9041562  0.89969516 0.89122635]\n",
            " [0.8849998  0.02184394 0.89245766 0.88848263 0.8882273 ]\n",
            " [0.8999666  0.0401361  0.8900874  0.9084372  0.8931873 ]\n",
            " [0.92508954 0.0272311  0.9113435  0.92265236 0.9149497 ]\n",
            " [0.95074695 0.03361546 0.9277444  0.94971454 0.93282866]\n",
            " [0.94612706 0.02003711 0.9462862  0.94758606 0.9489006 ]\n",
            " [0.9539159  0.01983108 0.94705075 0.9534013  0.9500925 ]\n",
            " [0.9667064  0.02071055 0.96601313 0.96560216 0.96858674]\n",
            " [0.9766334  0.02139206 0.9663954  0.9726338  0.9702785 ]\n",
            " [0.97686255 0.02413314 0.97342986 0.9790193  0.97866046]\n",
            " [0.9867131  0.02091677 0.9831786  0.9847965  0.98715776]\n",
            " [0.9756407  0.02017213 0.9840197  0.9834282  0.9807368 ]\n",
            " [0.9905693  0.02265551 0.98574    0.98760915 0.9906183 ]\n",
            " [0.99530375 0.02192806 0.9916275  0.9916761  0.99011844]\n",
            " [0.9876676  0.02030656 0.9943801  0.99350053 0.99096435]\n",
            " [0.985835   0.01692002 0.9853195  0.9886354  0.98719627]\n",
            " [0.99469286 0.02110415 0.9896013  0.9904598  0.9887727 ]\n",
            " [0.9816733  0.02263482 0.9944565  0.99464077 0.98258233]\n",
            " [0.99686915 0.01860989 0.9855489  0.99361455 0.9888496 ]\n",
            " [0.9983964  0.01695926 1.         0.99714935 1.        ]\n",
            " [1.         0.02788793 0.9996941  1.         0.99980766]\n",
            " [0.97170806 0.04332177 0.9786673  0.9747243  0.9722394 ]\n",
            " [0.9638811  0.0371885  0.97629714 0.9730519  0.9570519 ]\n",
            " [0.9626211  0.02780536 0.95442927 0.96157324 0.9593589 ]\n",
            " [0.9613993  0.01682648 0.9684216  0.9664004  0.96520317]\n",
            " [0.9458598  0.02957994 0.9591316  0.9544656  0.9445942 ]\n",
            " [0.94082    0.01903603 0.9518296  0.94796616 0.94482493]\n",
            " [0.95326686 0.02349437 0.94185144 0.94933444 0.9404802 ]\n",
            " [0.96369016 0.02399851 0.9636428  0.9662103  0.9653954 ]\n",
            " [0.94353074 0.02622273 0.9587493  0.95644206 0.9498233 ]\n",
            " [0.93990356 0.03044008 0.93458766 0.93694365 0.9323289 ]\n",
            " [0.912299   0.03339573 0.92548877 0.9285057  0.9150266 ]\n",
            " [0.9276858  0.02653784 0.9240743  0.9331428  0.92790717]\n",
            " [0.9472343  0.02094698 0.9385254  0.94674987 0.94355613]\n",
            " [0.9358946  0.02201703 0.94223374 0.9369056  0.9359816 ]\n",
            " [0.9278767  0.01735237 0.9411633  0.9362215  0.9335977 ]\n",
            " [0.9301728  0.02276459 0.9145549  0.92413473 0.9170644 ]\n",
            " [0.94303113 0.01893831 0.9323321  0.9420748  0.9372888 ]\n",
            " [0.93801796 0.01899892 0.94613326 0.9435191  0.9406724 ]\n",
            " [0.9594868  0.01856025 0.9469743  0.9542756  0.95132285]\n",
            " [0.96308404 0.01495923 0.9621901  0.960319   0.9640497 ]\n",
            " [0.96220386 0.0150246  0.9608902  0.96104115 0.9637805 ]\n",
            " [0.95386124 0.02147365 0.9598962  0.95549184 0.9580131 ]\n",
            " [0.95527714 0.01550892 0.9592463  0.9577724  0.95920503]\n",
            " [0.94655186 0.02029413 0.96012557 0.9547697  0.9492082 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6JQPNTN1Hwk"
      },
      "source": [
        "We can calculate the accuracy by counting the number of positive profits.\n",
        "total profit = sum of buy profit + sum of sell profit\n",
        "dividing it with number of testing samples to get profit per trade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8ai1iFjOsUP"
      },
      "source": [
        "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
        "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
        "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
        "total_profit = total_buy_profit + total_sell_profit\n",
        "profit_per_trade = total_profit / len(final_df)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_oBkuTINdyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "979c537c-fc39-41a4-851a-c9df72a74661"
      },
      "source": [
        "print(f\"{LOSS} loss:\", loss)\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
        "plot_graph(final_df)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "huber_loss loss: 0.00013594912888947874\n",
            "Mean Absolute Error: 2.930692600726924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zri7JFXrOunL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e067651-dcb5-491e-8bdf-bf820487909f"
      },
      "source": [
        "# printing values\n",
        "\n",
        "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
        "print(\"Accuracy score:\", accuracy_score)\n",
        "print(\"Total buy profit:\", total_buy_profit)\n",
        "print(\"Total sell profit:\", total_sell_profit)\n",
        "print(\"Total profit:\", total_profit)\n",
        "print(\"Profit per trade:\", profit_per_trade)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Future price after 15 days is 260.87$\n",
            "Accuracy score: 0.5201361315938741\n",
            "Total buy profit: 659.1416983604431\n",
            "Total sell profit: 18.212998121976852\n",
            "Total profit: 677.35469648242\n",
            "Profit per trade: 0.3842057268760181\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}